{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "import json\n",
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first read in the data. Our data is borrowed from https://github.com/AshwanthRamji/Depression-Sentiment-Analysis-with-Twitter-Data, and corresponds to parsed tweets. We can filter the tweets to only consider tweets with negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.read_csv(\"data/sentiment.csv\").set_index(\"id\")[\"sentiment\"]\n",
    "tweets = []\n",
    "f = open(\"data/tweetdata.txt\",)\n",
    "for line in f.readlines():\n",
    "    line = line.strip()\n",
    "    if len(line) == 0:\n",
    "        continue\n",
    "    curr_data = json.loads(line)\n",
    "    id_ = int(curr_data[\"id_str\"])\n",
    "    if id_ in sentiment and sentiment[id_] == -1:\n",
    "        tweet = curr_data[\"text\"].lower()\n",
    "        if \"spinner\" not in tweet or \"hand\" not in tweet: # manually filter spam\n",
    "            tweets.append(tweet)\n",
    "\n",
    "tweets = np.unique(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now tokenize all of the tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tk = TweetTokenizer()\n",
    "tokenized = [[\"<s>\"] + tk.tokenize(tweet) + [\"</s>\"] for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets all of the ngrams and their counts for the given dataset\n",
    "def get_ngram_counts(tweets, n):\n",
    "    counts = {}\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet) - n + 1):\n",
    "            ngram = \" \".join(tweet[i:i+n])\n",
    "            counts[ngram] = counts.get(ngram, 0) + 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, we will be using n = 3 for our ngrams. Let's compute the counts of ngrams and print out some of the most prevalent ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get rid of 13\n",
      "depression . </s> 21\n",
      "8 depression myths 12\n",
      "depression myths we 12\n",
      "myths we need 12\n",
      "we need to 13\n",
      "need to stop 12\n",
      "to stop believing 12\n",
      "stop believing ... 12\n",
      "the great depression 12\n",
      "my anxiety is 19\n",
      "mental health issues 12\n",
      "so much anxiety 14\n",
      "stress and anxiety 12\n",
      ", depression , 11\n",
      "<s> how to 16\n",
      ": me : 11\n",
      "<s> my anxiety 18\n"
     ]
    }
   ],
   "source": [
    "counts = get_ngram_counts(tokenized, 3)\n",
    "for gram, count in counts.items():\n",
    "    if count > 10:\n",
    "        print(gram, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the ngrams to a filterable dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_df = pd.DataFrame(counts.items(), columns=[\"ngram\", \"count\"])\n",
    "\n",
    "start_ngrams = ngrams_df[ngrams_df.ngram.str.startswith(\"<s>\")].copy()\n",
    "start_ngrams[\"count\"] /= start_ngrams[\"count\"].sum()\n",
    "\n",
    "other_ngrams = ngrams_df[~ngrams_df.ngram.str.startswith(\"<s>\")].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now write our tweet generation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_tweet(start_ngrams, other_ngrams, n, gen_count):\n",
    "    for i in range(gen_count):\n",
    "        start = np.random.choice(start_ngrams[\"ngram\"], p=start_ngrams[\"count\"]).split(\" \")\n",
    "        tweet = start\n",
    "\n",
    "        while tweet[-1] != \"</s>\":\n",
    "            curr_choices = other_ngrams[other_ngrams.ngram.str.startswith(\" \".join(tweet[-n+1:]) + \" \")].copy()\n",
    "            curr_choices[\"count\"] /= curr_choices[\"count\"].sum()\n",
    "            curr = np.random.choice(curr_choices[\"ngram\"], p=curr_choices[\"count\"]).split(\" \")\n",
    "            tweet.append(curr[-1])\n",
    "\n",
    "        print(\" \".join(tweet[1:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt @alyciatyre : my heart goes out to those of us whose anxiety has gone from crippling to an accelerating vomit / shit / deathlike ever since â€¦\n",
      "depression , but i don't wish them upon anybody .\n",
      "que anxiety ni que la chingada ponte a limpiar ðŸ˜‚ ðŸ˜‚ ðŸ˜‹ by alot of using their minds ðŸ˜‚ ðŸ˜‚\n",
      "i have depression \" just because i'm thinking of something more important to me feeling so tired and sick lately i haven't been able to go in @checkpointorg ' s kami dvorakova â€¦\n",
      "post 1am depression twitter https://t.co/ibmpn4kn8l\n",
      "rt @kbelliard_ : nothing hurts more than depression , they're not thinking about life , you know what's really fun about bipolar disorder - anxiety is acting so badly rn lmao\n",
      "rt @playstationau : 24 hours to go to a therapist every month and always have panic attacks and anxiety https://t.co/gmhp3ldode\n",
      "my parents feel like there's something missing and that's why my depression ? https://t.co/tg3oxxndgl\n",
      "talkin bout cancer ðŸ˜© ðŸ˜© ðŸ˜© ðŸ˜© ðŸ˜© ðŸ˜© ðŸ˜© ðŸ˜© ðŸ˜©\n",
      "i don't wanna talk until tomorrow ðŸŽ¶\n"
     ]
    }
   ],
   "source": [
    "gen_tweet(start_ngrams, other_ngrams, 3, 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
